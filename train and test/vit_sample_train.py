import os
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
from torch import optim
from torch.utils.data import Dataset, DataLoader, ConcatDataset
from torch.utils.tensorboard import SummaryWriter
from torchvision import transforms
from torchvision.models import mobilenet_v2
from transformers import ViTModel, ViTConfig
import pandas as pd
import time
from datetime import datetime

# ========== Configuration Parameters ==========
epochs_to_save = [20]
total_epochs = epochs_to_save[-1]  # æ€»å…±è®­ç»ƒ40ä¸ªepoch

lr = 0.0001
batch_size = 64
weight_decay = 0.05
model_load_path = None
train_data_dir = '/root/autodl-tmp/train'
val_data_dir = '/root/autodl-tmp/val'
height_threshold = 4.5

# å®šä¹‰å¤šä¸ªsampling_N_listç»„åˆ
sampling_N_combinations = [
    [6,12,14,18]
]

# ä¿®æ”¹æ¨¡å‹ä¿å­˜è·¯å¾„æ ¼å¼
base_model_save_dir = '/root/autodl-tmp/program/model_vit/model_vit/sample_1/'
base_tensorboard_dir = '/root/autodl-tmp/tensorboard_logs_vit'

# æ—©åœæœºåˆ¶å‚æ•°
patience = 10  # åœ¨éªŒè¯é›†ä¸Šæ€§èƒ½æ²¡æœ‰æå‡çš„epochæ•°
min_delta = 0.0001  # è®¤ä¸ºæœ‰æå‡çš„æœ€å°å˜åŒ–é‡

# Excelè®°å½•æ–‡ä»¶è·¯å¾„
excel_log_path = '/root/autodl-tmp/computational_efficiency_stats_vit.xlsx'


# ========== Early Stopping Class ==========
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0, verbose=True):
        self.patience = patience
        self.min_delta = min_delta
        self.verbose = verbose
        self.counter = 0
        self.best_score = None
        self.early_stop = False
        self.val_loss_min = np.Inf

    def __call__(self, val_loss, model, model_save_path):
        score = -val_loss

        if self.best_score is None:
            self.best_score = score
            self.save_checkpoint(val_loss, model, model_save_path)
        elif score < self.best_score + self.min_delta:
            self.counter += 1
            if self.verbose:
                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_score = score
            self.save_checkpoint(val_loss, model, model_save_path)
            self.counter = 0

    def save_checkpoint(self, val_loss, model, model_save_path):
        '''Saves model when validation loss decrease.'''
        if self.verbose:
            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...')
        torch.save(model.state_dict(), model_save_path)
        self.val_loss_min = val_loss


# ========== ViT Model ==========
class ViT(nn.Module):
    def __init__(self, num_classes=2, pretrained_weight_path=None, target_image_size=16):
        super().__init__()
        self.target_image_size = target_image_size
        self.mobilenet_input_size = 224

        # è¾“å…¥é¢„å¤„ç†ï¼ˆä¸MobileNetç›¸åŒï¼‰
        self.adaptive_pool = nn.AdaptiveAvgPool2d((self.mobilenet_input_size, self.mobilenet_input_size))

        # ä¿®æ”¹ MobileNetV2 å¹¶ç¦ç”¨å…¨å±€æ± åŒ–
        self.backbone = mobilenet_v2(pretrained=False)
        self.backbone.features[0][0] = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)
        self.backbone.classifier = nn.Identity()
        self.backbone.avgpool = nn.Identity()  # å…³é”®ï¼šç¦ç”¨å…¨å±€æ± åŒ–

        # æŠ•å½±å±‚
        self.projection = nn.Sequential(
            nn.Conv2d(1280, 32, kernel_size=1),  # è¾“å…¥ [B, 1280, 7, 7]
            nn.BatchNorm2d(32),
            nn.GELU(),
            nn.AdaptiveAvgPool2d((target_image_size, target_image_size))  # è¾“å‡º [B, 32, 16, 16]
        )

        # ViT é…ç½®
        config = ViTConfig(
            image_size=target_image_size,
            patch_size=4,
            num_channels=32,
            hidden_size=768,
            num_hidden_layers=12,
            num_attention_heads=12,
            intermediate_size=3072,
            hidden_dropout_prob=0.1,
            attention_probs_dropout_prob=0.1,
            classifier_dropout=0.1,
        )
        self.vit = ViTModel(config)
        self.classifier = nn.Linear(config.hidden_size, num_classes)

    def forward(self, x):
        x = self.adaptive_pool(x)  # [B, 1, H, W] -> [B, 1, 224, 224]
        x = self.backbone.features(x)  # [B, 1, 224, 224] -> [B, 1280, 7, 7]
        x = self.projection(x)  # [B, 1280, 7, 7] -> [B, 32, 16, 16]
        outputs = self.vit(x)  # ViT å¤„ç†
        sequence_output = outputs.last_hidden_state
        features = sequence_output.mean(dim=1) + sequence_output.max(dim=1).values
        return self.classifier(features)


# ========== Image Sampler ==========
class ImageSampler:
    def __init__(self, image_dir, N=11, alpha=None):
        self.image_dir = image_dir
        self.sampling_N = N
        self.alpha = alpha
        self.image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.tiff')])

    def sample_single_image(self, img_path):
        try:
            with Image.open(img_path) as img:
                img = np.array(img).astype(np.float32)
        except Exception as e:
            print(f"Error reading image {img_path}: {e}")
            return None, None

        h, w = img.shape
        x_coords = np.linspace(0, w - 1, self.sampling_N, dtype=int)
        y_coords = np.linspace(0, h - 1, self.sampling_N, dtype=int)
        X, Y = np.meshgrid(x_coords, y_coords)
        sampled_values = img[Y, X]

        sample_tensor = torch.FloatTensor(sampled_values).unsqueeze(0)  # Shape: [1, N, N]

        label = 0
        if self.alpha is not None:
            max_pixel_value = np.max(img)
            label = 1 if max_pixel_value >= self.alpha else 0

        return sample_tensor, label


# ========== Dataset Classes ==========
class HeightThresholdDataset(Dataset):
    def __init__(self, image_dir, sampling_N, alpha, transform=None):
        self.image_dir = image_dir
        self.sampling_N = sampling_N
        self.alpha = alpha
        self.transform = transform
        self.sampler = ImageSampler(image_dir, sampling_N, alpha)
        self.image_files = self.sampler.image_files

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_path = os.path.join(self.image_dir, self.image_files[idx])
        sample, label = self.sampler.sample_single_image(img_path)

        if sample is None or label is None:
            # Return placeholder if sampling failed
            sample = torch.zeros((1, self.sampling_N, self.sampling_N))
            label = 0

        if self.transform:
            sample = self.transform(sample)

        return sample, torch.tensor(label, dtype=torch.long)


# Data preprocessing
transform = transforms.Compose([
    transforms.Normalize(mean=[0.5], std=[0.5])  # Single channel normalization
])


# Custom collate function for handling different input sizes
def collate_fn(batch):
    size_groups = {}
    for sample, label in batch:
        size_key = sample.shape[-1]  # Get sampling size N
        if size_key not in size_groups:
            size_groups[size_key] = []
        size_groups[size_key].append((sample, label))

    batched_samples = []
    batched_labels = []
    for size, group in size_groups.items():
        samples = torch.stack([item[0] for item in group])
        labels = torch.stack([item[1] for item in group])

        num_samples = len(samples)
        if num_samples < batch_size:
            repeat_times = batch_size // num_samples + 1
            samples = samples.repeat(repeat_times, *[1] * (samples.dim() - 1))[:batch_size]
            labels = labels.repeat(repeat_times)[:batch_size]

        batched_samples.append(samples)
        batched_labels.append(labels)

    return batched_samples, batched_labels


def train_model_with_sampling_N(sampling_N_list, model_save_dir, tensorboard_dir):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹ï¼Œä½¿ç”¨æŒ‡å®šçš„sampling_N_listç»„åˆ"""
    print(f"\n{'=' * 60}")
    print(f"Training ViT model with sampling_N_list: {sampling_N_list}")
    print(f"{'=' * 60}")

    start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´

    # ========== Data Loading ==========
    print("Loading datasets...")

    # è®­ç»ƒé›†ï¼šä½¿ç”¨sampling_N_listä¸­çš„æ‰€æœ‰é‡‡æ ·å€¼
    all_train_datasets = []
    for sampling_N in sampling_N_list:
        dataset = HeightThresholdDataset(train_data_dir, sampling_N, height_threshold, transform)
        all_train_datasets.append(dataset)

    # éªŒè¯é›†ï¼šä½¿ç”¨ä¸è®­ç»ƒé›†ç›¸åŒçš„sampling_N_listç»„åˆ
    all_val_datasets = []
    for sampling_N in sampling_N_list:
        dataset = HeightThresholdDataset(val_data_dir, sampling_N, height_threshold, transform)
        all_val_datasets.append(dataset)

    train_dataset = ConcatDataset(all_train_datasets)
    val_dataset = ConcatDataset(all_val_datasets)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)

    # ========== Training Setup ==========
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # åˆ›å»ºViTæ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°å’ŒTensorBoard writer
    model = ViT(num_classes=2).to(device)
    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)
    # æ·»åŠ ä½™å¼¦é€€ç«å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=total_epochs)
    writer = SummaryWriter(log_dir=tensorboard_dir)
    criterion = nn.CrossEntropyLoss()

    # åˆå§‹åŒ–æ—©åœæœºåˆ¶
    early_stopping = EarlyStopping(patience=patience, min_delta=min_delta, verbose=True)
    model_save_path = os.path.join(model_save_dir, 'model_vit.pth')

    print(f"Starting ViT training for {total_epochs} epochs")
    print(f"Model will be saved with early stopping")
    print(f"Training samples: {len(train_dataset)}")
    print(f"Validation samples: {len(val_dataset)}")
    print(f"Early stopping patience: {patience} epochs")
    print(f"Batch size: {batch_size}")
    print(f"Learning rate: {lr}")
    print(f"Number of sampling resolutions: {len(sampling_N_list)}")
    print(f"Sampling resolutions: {sampling_N_list}")

    # ========== Training Loop ==========
    total_training_time = 0
    actual_epochs_trained = 0
    epoch_times = []

    for epoch in range(total_epochs):
        epoch_start_time = time.time()
        model.train()
        train_loss, train_correct, total_samples = 0.0, 0, 0
        train_batches = 0

        # è®­ç»ƒé˜¶æ®µ
        for batch_idx, (batch_samples, batch_labels) in enumerate(train_loader):
            for samples, labels in zip(batch_samples, batch_labels):
                samples, labels = samples.to(device), labels.to(device)

                optimizer.zero_grad()
                outputs = model(samples)
                loss = criterion(outputs, labels)
                loss.backward()
                optimizer.step()

                train_loss += loss.item() * samples.size(0)
                _, preds = torch.max(outputs, 1)
                train_correct += (preds == labels).sum().item()
                total_samples += samples.size(0)
                train_batches += 1

        # åœ¨æ¯ä¸ªepochç»“æŸæ—¶æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        current_lr = optimizer.param_groups[0]['lr']

        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        epoch_train_loss = train_loss / total_samples if total_samples > 0 else 0
        epoch_train_acc = 100 * train_correct / total_samples if total_samples > 0 else 0

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss, val_correct, val_total = 0.0, 0, 0
        val_batches = 0

        with torch.no_grad():
            for batch_samples, batch_labels in val_loader:
                for samples, labels in zip(batch_samples, batch_labels):
                    samples, labels = samples.to(device), labels.to(device)
                    outputs = model(samples)
                    loss = criterion(outputs, labels)
                    val_loss += loss.item() * samples.size(0)
                    _, preds = torch.max(outputs, 1)
                    val_correct += (preds == labels).sum().item()
                    val_total += samples.size(0)
                    val_batches += 1

        # è®¡ç®—éªŒè¯æŒ‡æ ‡
        epoch_val_loss = val_loss / val_total if val_total > 0 else 0
        epoch_val_acc = 100 * val_correct / val_total if val_total > 0 else 0

        epoch_time = time.time() - epoch_start_time
        total_training_time += epoch_time
        epoch_times.append(epoch_time)
        actual_epochs_trained = epoch + 1

        # è¯¦ç»†æ‰“å°æ¯ä¸ªepochçš„ä¿¡æ¯
        print(f"\n{'=' * 80}")
        print(f"Epoch {epoch + 1}/{total_epochs} - ViT Model")
        print(f"{'=' * 80}")

        # æ—¶é—´ä¿¡æ¯
        print(f"â° Time Metrics:")
        print(f"   - Epoch Time: {epoch_time:.2f}s")
        print(f"   - Cumulative Time: {total_training_time:.2f}s ({total_training_time / 60:.2f} minutes)")

        # è®­ç»ƒä¿¡æ¯
        print(f"ğŸ“Š Training Metrics:")
        print(f"   - Loss: {epoch_train_loss:.4f}")
        print(f"   - Accuracy: {epoch_train_acc:.2f}%")
        print(f"   - Correct/Total: {train_correct}/{total_samples}")
        print(f"   - Batches Processed: {train_batches}")

        # éªŒè¯ä¿¡æ¯
        print(f"ğŸ” Validation Metrics:")
        print(f"   - Loss: {epoch_val_loss:.4f}")
        print(f"   - Accuracy: {epoch_val_acc:.2f}%")
        print(f"   - Correct/Total: {val_correct}/{val_total}")
        print(f"   - Batches Processed: {val_batches}")

        # å­¦ä¹ ç‡å’Œä¼˜åŒ–ä¿¡æ¯
        print(f"âš™ï¸  Optimization Metrics:")
        print(f"   - Learning Rate: {current_lr:.2e}")
        print(f"   - Early Stopping Counter: {early_stopping.counter}/{patience}")

        # è¿›åº¦ä¿¡æ¯
        progress = (epoch + 1) / total_epochs * 100
        print(f"ğŸ“ˆ Progress:")
        print(f"   - Progress: {progress:.1f}% ({epoch + 1}/{total_epochs})")
        print(f"   - Estimated Remaining Time: {(total_epochs - epoch - 1) * np.mean(epoch_times):.2f}s")

        # Log to TensorBoard
        writer.add_scalar('Loss/Train', epoch_train_loss, epoch)
        writer.add_scalar('Accuracy/Train', epoch_train_acc, epoch)
        writer.add_scalar('Loss/Val', epoch_val_loss, epoch)
        writer.add_scalar('Accuracy/Val', epoch_val_acc, epoch)
        writer.add_scalar('Learning Rate', current_lr, epoch)
        writer.add_scalar('Time/Epoch', epoch_time, epoch)

        # æ—©åœæœºåˆ¶æ£€æŸ¥
        early_stopping(epoch_val_loss, model, model_save_path)

        if early_stopping.early_stop:
            print(f"\nğŸš¨ Early stopping triggered at epoch {epoch + 1}!")
            print(f"   - Best validation loss: {early_stopping.val_loss_min:.6f}")
            print(f"   - Total epochs trained: {actual_epochs_trained}")
            break

    # è®¡ç®—æ€»è®­ç»ƒæ—¶é—´
    total_training_time = time.time() - start_time

    # æ”¶é›†è®¡ç®—æ•ˆç‡ç»Ÿè®¡ä¿¡æ¯
    stats = {
        # æ¨¡å‹è¯†åˆ«ä¿¡æ¯
        'Model_ID': f"vit_model_{'_'.join(map(str, sampling_N_list))}",
        'Sampling_Resolutions': str(sampling_N_list),
        'Training_Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),

        # æ•°æ®æ•ˆç‡æŒ‡æ ‡
        'Num_Resolutions': len(sampling_N_list),
        'Training_Samples': len(train_dataset),
        'Validation_Samples': len(val_dataset),
        'Data_Reduction_Ratio': f"{len(sampling_N_list)}/{len(sampling_N_combinations[0])}",
        'Efficiency_Gain_Percentage': f"{(1 - len(sampling_N_list) / len(sampling_N_combinations[0])) * 100:.1f}%",

        # æ—¶é—´æ•ˆç‡æŒ‡æ ‡
        'Total_Training_Time_Seconds': total_training_time,
        'Total_Training_Time_Minutes': total_training_time / 60,
        'Average_Epoch_Time_Seconds': np.mean(epoch_times),
        'Std_Epoch_Time_Seconds': np.std(epoch_times),
        'Min_Epoch_Time_Seconds': np.min(epoch_times),
        'Max_Epoch_Time_Seconds': np.max(epoch_times),

        # æ”¶æ•›æ•ˆç‡æŒ‡æ ‡
        'Total_Epochs_Planned': total_epochs,
        'Actual_Epochs_Trained': actual_epochs_trained,
        'Early_Stopping_Triggered': early_stopping.early_stop,
        'Best_Val_Loss': early_stopping.val_loss_min,

        # è®­ç»ƒé…ç½®
        'Batch_Size': batch_size,
        'Final_Train_Accuracy': epoch_train_acc,
        'Final_Val_Accuracy': epoch_val_acc
    }

    print(f"\n{'=' * 80}")
    print(f"ğŸ ViT Training Completed Summary for {sampling_N_list}")
    print(f"{'=' * 80}")
    print(f"âœ… Total training time: {total_training_time:.2f}s ({total_training_time / 60:.2f} minutes)")
    print(f"âœ… Average epoch time: {np.mean(epoch_times):.2f}s")
    print(f"âœ… Data reduction: {stats['Efficiency_Gain_Percentage']}")
    print(f"âœ… Actual epochs trained: {actual_epochs_trained}/{total_epochs}")
    print(f"âœ… Final Train Accuracy: {epoch_train_acc:.2f}%")
    print(f"âœ… Final Val Accuracy: {epoch_val_acc:.2f}%")
    print(f"âœ… Best Validation Loss: {early_stopping.val_loss_min:.6f}")

    writer.close()

    return stats


# ========== Main Training Loop for Multiple Models ==========
if __name__ == "__main__":
    # åˆ›å»ºDataFrameæ¥å­˜å‚¨æ‰€æœ‰ç»Ÿè®¡ä¿¡æ¯
    all_stats = []

    for i, sampling_N_list in enumerate(sampling_N_combinations):
        # ä¸ºæ¯ä¸ªæ¨¡å‹ç»„åˆåˆ›å»ºç‹¬ç«‹çš„ç›®å½•
        sampling_str = "_".join(map(str, sampling_N_list))
        model_save_dir = os.path.join(base_model_save_dir, f"model_{sampling_str}")
        tensorboard_dir = os.path.join(base_tensorboard_dir, f"model_{sampling_str}")

        os.makedirs(model_save_dir, exist_ok=True)
        os.makedirs(tensorboard_dir, exist_ok=True)

        # è®­ç»ƒå½“å‰ç»„åˆçš„æ¨¡å‹ï¼ˆéªŒè¯é›†ä½¿ç”¨ç›¸åŒçš„é‡‡æ ·ç»„åˆï¼‰
        stats = train_model_with_sampling_N(sampling_N_list, model_save_dir, tensorboard_dir)
        all_stats.append(stats)

    # å°†ç»Ÿè®¡ä¿¡æ¯ä¿å­˜åˆ°Excel
    df = pd.DataFrame(all_stats)

    # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåºï¼Œè®©é‡è¦ä¿¡æ¯åœ¨å‰é¢
    column_order = [
        'Model_ID',
        'Sampling_Resolutions',
        'Num_Resolutions',
        'Data_Reduction_Ratio',
        'Efficiency_Gain_Percentage',
        'Training_Samples',
        'Validation_Samples',
        'Total_Training_Time_Seconds',
        'Total_Training_Time_Minutes',
        'Average_Epoch_Time_Seconds',
        'Std_Epoch_Time_Seconds',
        'Min_Epoch_Time_Seconds',
        'Max_Epoch_Time_Seconds',
        'Total_Epochs_Planned',
        'Actual_Epochs_Trained',
        'Early_Stopping_Triggered',
        'Best_Val_Loss',
        'Final_Train_Accuracy',
        'Final_Val_Accuracy',
        'Batch_Size',
        'Training_Date'
    ]

    df = df[column_order]

    # ä¿å­˜åˆ°Excel
    df.to_excel(excel_log_path, index=False, engine='openpyxl')

    print(f"\n{'=' * 80}")
    print(f"ğŸ‰ All ViT models training completed!")
    print(f"ğŸ“Š Total models trained: {len(sampling_N_combinations)}")
    print(f"ğŸ’¾ Computational efficiency statistics saved to: {excel_log_path}")
    print(f"{'=' * 80}")

    # æ‰“å°è®¡ç®—æ•ˆç‡æ±‡æ€»ç»Ÿè®¡
    print("\nğŸ“ˆ Computational Efficiency Summary:")
    print(
        f"   Average training time: {df['Total_Training_Time_Seconds'].mean():.2f}s ({df['Total_Training_Time_Minutes'].mean():.2f} minutes)")
    print(f"   Average epoch time: {df['Average_Epoch_Time_Seconds'].mean():.2f}s")
    print(f"   Average data reduction: {df['Efficiency_Gain_Percentage'].iloc[0]}")
    print(f"   Average actual epochs: {df['Actual_Epochs_Trained'].mean():.1f}")
    print(f"   Average final validation accuracy: {df['Final_Val_Accuracy'].mean():.2f}%")